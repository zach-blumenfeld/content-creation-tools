{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Written Marketing Content Grounded with your Message and Positioning Framework (MPF)\n",
    "\n",
    "This requires building a Knowledge Graph from your MPF in Neo4j. You can use the Neo4j Labs [LLM Graph Builder](https://github.com/neo4j-labs/llm-graph-builder) to accomplish this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "SOURCE_MATERIAL_TXT_FILE = 'transcript.txt'\n",
    "OUTPUT_FILE = 'summary.txt'\n",
    "NUM_VERSIONS = 4\n",
    "TASK_PROMPT = \"\"\"\n",
    "You are an expert Marketer for Neo4j, the Graph Database and Analytics company.\n",
    "You must create a Youtube title and description for our new GenAI Hero Demo using the Source Transcript below. The description should be engaging and encourage people to want to learn more.\n",
    "Also, below the Source Transcript is the Messaging Framework which you should use as context to guide the formation of the title and description. The Messaging Framework will tell you about the strengths of Neo4j to highlight as we as the target audience you are writing for.\n",
    "\n",
    "# Source Transcript\n",
    "{taskMaterials}\n",
    "\n",
    "# Messaging Framework\n",
    "{messagingFramework}\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(TASK_PROMPT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# You can skip this cell if not using a ws.env file - alternative to above\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# Neo4j\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "AURA_DS = eval(os.getenv('AURA_DS').title())\n",
    "\n",
    "# AI\n",
    "LLM = 'gpt-4'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "embedding_dimension = 1536"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "#Instantiate LLM\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=LLM, streaming=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "neo4jStore = Neo4jVector.from_existing_index(\n",
    "        embedding=embedding_model,\n",
    "        url=NEO4J_URI,\n",
    "        username=NEO4J_USERNAME,\n",
    "        password=NEO4J_PASSWORD,\n",
    "        index_name='vector',\n",
    "        retrieval_query=\"\"\"\n",
    "        WITH node AS chunk, score\n",
    "        MATCH (chunk)-[:PART_OF]->(doc)\n",
    "        OPTIONAL MATCH (chunk)<-[:NEXT_CHUNK]-(pc)\n",
    "        OPTIONAL MATCH (chunk)-[:NEXT_CHUNK]->(nc)\n",
    "        RETURN coalesce(pc.text,'') + chunk.text + coalesce(nc.text,'') AS text,\n",
    "            score,\n",
    "            {source: doc.fileName} AS metadata\n",
    "        ORDER BY score DESC\n",
    "    \"\"\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "kg_retriever = neo4jStore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = ({'messagingFramework': kg_retriever | format_docs,\n",
    "          'taskMaterials':  RunnablePassthrough()}\n",
    "         | prompt\n",
    "         | llm\n",
    "         | StrOutputParser())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with open(SOURCE_MATERIAL_TXT_FILE, \"r\") as f:\n",
    "    txt = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "response = chain.invoke(txt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:36<00:00,  9.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(OUTPUT_FILE, \"a\") as out_txt_file:\n",
    "    for i in tqdm(range(NUM_VERSIONS)):\n",
    "        out_txt_file.write(f'#Response {i}\\n')\n",
    "        out_txt_file.write(chain.invoke(txt))\n",
    "        out_txt_file.write('\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
